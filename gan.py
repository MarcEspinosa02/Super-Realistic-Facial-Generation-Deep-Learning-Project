# -*- coding: utf-8 -*-
"""GAN_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Js4Y0ckoHjo6jMSNMSi8Q2EKrFEIbocc
"""

import os
import math
import sys
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

import torchvision.transforms as transforms
from torchvision.utils import save_image

from torch.utils.data import DataLoader
from torchvision import datasets
from torch.autograd import Variable

import torch.nn as nn
import torch.nn.functional as F
import torch

# Mount Google Drive
drive.mount('/content/drive')
data_path = '/content/drive/Shareddrives/DEEP LEARNING/DeepLearning_2021/Final/Data/'
results_path = '/content/drive/Shareddrives/DEEP LEARNING/DeepLearning_2021/Final/Results/StdGAN/'
IMAGE_PATH = '/content/drive/Shareddrives/DEEP LEARNING/DeepLearning_2021/Final/Data/img_align_celeba.zip'

img_shape = (3, 178, 218)

# ---------------------
#  Generator
# ---------------------
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat, 0.8))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *block(100, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *img_shape)
        return img

# ---------------------
#  Discriminator
# ---------------------
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.model = nn.Sequential(
            nn.Linear(int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid(),
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)

        return validity

cuda = True if torch.cuda.is_available() else False

# Loss function
adversarial_loss = torch.nn.BCELoss()

# Initialize generator and discriminator
generator = Generator()
discriminator = Discriminator()

if cuda:
    generator.cuda()
    discriminator.cuda()
    adversarial_loss.cuda()

# Creation of the directory in local memory for the data and images unpacking
!mkdir '/content/imgs/'
!unzip -u '/content/drive/Shareddrives/DEEP LEARNING/DeepLearning_2021/Final/Data/img_align_celeba.zip' -d '/content/imgs/'
!ls


# ---------------------
#   Configure Data Loader
# ---------------------
tr = transforms.Compose([
               #transforms.Resize(64),
               #transforms.CenterCrop(64),
               transforms.ToTensor(),
               transforms.Normalize(mean=[0.5],
                            std=[0.5])
                ])

ImageFolder = datasets.ImageFolder('/content/imgs/', tr)

#celeb_data = datasets.CelebA(data_path, download = True, transform = tr)

test_size = 50000 #int( 0.4 * len(ImageFolder))
train_size = len(ImageFolder) - test_size
dataA,dataB = torch.utils.data.random_split(ImageFolder, [train_size, test_size]) 


dataloader = torch.utils.data.DataLoader(
    dataB,
    batch_size=64,
    shuffle=True,
    drop_last=True,
    num_workers=2
)

# Commented out IPython magic to ensure Python compatibility.
# Optimizers
lr = 0.0002
b1 = 0.5
b2 = 0.999
optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))

Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor

# ----------
#  Training
# ----------
n_epochs = 40
for epoch in range(n_epochs):
    for i, (imgs, _) in enumerate(dataloader):

        # Adversarial ground truths
        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)
        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)

        # Configure input
        real_imgs = Variable(imgs.type(Tensor))

        # -----------------
        #  Train Generator
        # -----------------

        optimizer_G.zero_grad()

        # Sample noise as generator input
        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100))))

        # Generate a batch of images
        gen_imgs = generator(z)

        # Loss measures generator's ability to fool the discriminator
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)

        g_loss.backward()
        optimizer_G.step()

        # ---------------------
        #  Train Discriminator
        # ---------------------

        optimizer_D.zero_grad()

        # Measure discriminator's ability to classify real from generated samples
        real_loss = adversarial_loss(discriminator(real_imgs), valid)
        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
        d_loss = (real_loss + fake_loss) / 2

        d_loss.backward()
        optimizer_D.step()

        print(
            "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]" % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())
        )

        batches_done = epoch * len(dataloader) + i
        if batches_done % 400 == 0:
            save_image(gen_imgs.data[:1], results_path+"%d_v2.png" % batches_done, nrow=5, normalize=True)
